{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brucecmd/tensorflow_in_action_code/blob/master/simple_mlp_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu29lMmv_lMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zSsfEnY_wCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQdnIwYW_zVQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "5f2bc1cb-2897-4ba1-da20-554afa6b6598"
      },
      "source": [
        "mnist = input_data.read_data_sets(\"./MNIST\", one_hot=True)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/train-images-idx3-ubyte.gz\n",
            "Extracting ./MNIST/train-labels-idx1-ubyte.gz\n",
            "Extracting ./MNIST/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./MNIST/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE-49eAX_2zD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f84a1c3c-5b89-4604-8007-0fe395e9eb1d"
      },
      "source": [
        "print(mnist.train.num_examples)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1alTe8A_8Y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_node = 784\n",
        "output_node = 10\n",
        "\n",
        "layer1_node = 500\n",
        "batch_size = 100\n",
        "\n",
        "learning_rate_base = 0.8\n",
        "learning_rate_decay = 0.99\n",
        "\n",
        "regularization_rate = 0.0001\n",
        "traininig_steps = 30000\n",
        "moving_average_decay = 0.99\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KpRnlYzARbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inference(input_tensor, avg_class, weights1, biases1, weights2, biases2):\n",
        "  if avg_class == None:\n",
        "    layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + biases1)\n",
        "    return tf.matmul(layer1, weights2) + biases2\n",
        "  else:\n",
        "    layer1 = tf.nn.relu(tf.matmul(input_tensor, avg_class.average(weights1)) + avg_class.average(biases1))\n",
        "    return tf.matmul(layer1, avg_class.average(weights2)) + avg_class.average(biases2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zIiRU63A1af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(mnist):\n",
        "  x = tf.placeholder(tf.float32, [None, input_node], name=\"x-input\")\n",
        "  y_ = tf.placeholder(tf.float32, [None, 10], name=\"y-input\")\n",
        "  \n",
        "  # 用于训练的参数\n",
        "  weights1 = tf.Variable(tf.truncated_normal([input_node, layer1_node], stddev=0.1))\n",
        "  biases1 = tf.Variable(tf.constant(0.1, shape=[layer1_node]))\n",
        "  weights2 = tf.Variable(tf.truncated_normal([layer1_node, output_node], stddev=0.1))\n",
        "  biases2 = tf.Variable(tf.constant(0.1, shape=[output_node]))\n",
        "  \n",
        "  y = inference(x, None, weights1, biases1, weights2, biases2)\n",
        "  \n",
        "  # 准备滑动平均相关的东西\n",
        "  global_step = tf.Variable(0, trainable=False)\n",
        "  variable_averages = tf.train.ExponentialMovingAverage(moving_average_decay, global_step)\n",
        "  variable_averages_op = variable_averages.apply(tf.trainable_variables()) # 注意，tf.trainable_variables()要加括号，不然报错\n",
        "  \n",
        "  average_y = inference(x, variable_averages, weights1, biases1, weights2, biases2)\n",
        "  \n",
        "  cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_,1))\n",
        "  cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
        "  \n",
        "  regularizer = tf.contrib.layers.l2_regularizer(regularization_rate)\n",
        "  regularization = regularizer(weights1) + regularizer(weights2)\n",
        "  loss = cross_entropy_mean + regularization\n",
        "  \n",
        "  learning_rate = tf.train.exponential_decay(learning_rate_base, global_step, mnist.train.num_examples/batch_size, learning_rate_decay)\n",
        "  \n",
        "  train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
        "  \n",
        "  with tf.control_dependencies([train_step, variable_averages_op]):\n",
        "    train_op = tf.no_op(name='train')\n",
        "    \n",
        "  correct_prediction = tf.equal(tf.argmax(average_y, 1), tf.argmax(y_,1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "  \n",
        "  with tf.Session() as sess:\n",
        "    tf.global_variables_initializer().run()\n",
        "    validate_feed = {x:mnist.validation.images,y_:mnist.validation.labels}\n",
        "    test_feed = {x:mnist.test.images, y_:mnist.test.labels}\n",
        "    \n",
        "    for i in range(traininig_steps):\n",
        "      if i % 1000 == 0:\n",
        "        validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n",
        "        print(\"after %d steps, validation acc %g\"%(i, validate_acc))\n",
        "      xs,ys = mnist.train.next_batch(batch_size)\n",
        "      sess.run(train_op, feed_dict={x:xs,y_:ys})\n",
        "    test_acc = sess.run(accuracy, feed_dict=test_feed)\n",
        "    print(\"after %d steps, acc is : %g\"%(traininig_steps, test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kOP2_rCEdUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "outputId": "c2ea6b38-8d9e-4620-f44d-346885ff847d"
      },
      "source": [
        "train(mnist)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "after 0 steps, validation acc 0.0962\n",
            "after 1000 steps, validation acc 0.9764\n",
            "after 2000 steps, validation acc 0.98\n",
            "after 3000 steps, validation acc 0.983\n",
            "after 4000 steps, validation acc 0.9828\n",
            "after 5000 steps, validation acc 0.983\n",
            "after 6000 steps, validation acc 0.9834\n",
            "after 7000 steps, validation acc 0.9836\n",
            "after 8000 steps, validation acc 0.9838\n",
            "after 9000 steps, validation acc 0.9836\n",
            "after 10000 steps, validation acc 0.9846\n",
            "after 11000 steps, validation acc 0.9848\n",
            "after 12000 steps, validation acc 0.9838\n",
            "after 13000 steps, validation acc 0.9842\n",
            "after 14000 steps, validation acc 0.9848\n",
            "after 15000 steps, validation acc 0.984\n",
            "after 16000 steps, validation acc 0.9848\n",
            "after 17000 steps, validation acc 0.985\n",
            "after 18000 steps, validation acc 0.9846\n",
            "after 19000 steps, validation acc 0.9844\n",
            "after 20000 steps, validation acc 0.9846\n",
            "after 21000 steps, validation acc 0.9848\n",
            "after 22000 steps, validation acc 0.9836\n",
            "after 23000 steps, validation acc 0.9844\n",
            "after 24000 steps, validation acc 0.9844\n",
            "after 25000 steps, validation acc 0.9846\n",
            "after 26000 steps, validation acc 0.9842\n",
            "after 27000 steps, validation acc 0.9844\n",
            "after 28000 steps, validation acc 0.9848\n",
            "after 29000 steps, validation acc 0.9848\n",
            "after 30000 steps, acc is : 0.9843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgCsAnWBEhQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}