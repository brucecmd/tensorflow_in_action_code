{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brucecmd/tensorflow_in_action_code/blob/master/%E5%88%9D%E6%AD%A5%E7%9A%84%E5%85%B8%E5%9E%8B%E4%BE%8B%E5%AD%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc9RZmKbNBRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ8h8GKlu1fH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_node = 784\n",
        "output_node = 10\n",
        "layer1_node = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7L043-tu7Uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_weight_variable(shape, regularizer):\n",
        "  weights = tf.get_variable(\"weights\", shape, initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
        "  if regularizer!=None:\n",
        "    tf.add_to_collection(\"losses\", regularizer(weights))\n",
        "  return weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUnGOWGswzIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inference(input_tensor, regularizer):\n",
        "  with tf.variable_scope(\"layer1\"):\n",
        "    weights = get_weight_variable([input_node, layer1_node], regularizer)\n",
        "    biases = tf.get_variable(\"biases\", [layer1_node], initializer=tf.constant_initializer(0.0))\n",
        "    layer1 = tf.nn.relu(tf.matmul(input_tensor, weights) + biases)\n",
        "  with tf.variable_scope(\"layer2\"):\n",
        "    weights = get_weight_variable([layer1_node,output_node], regularizer)\n",
        "    biases = tf.get_variable(\"biases\", [output_node], initializer=tf.constant_initializer(0.0))\n",
        "    layer2 = tf.matmul(layer1, weights) + biases\n",
        "  return layer2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hurj_zNMxsFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTXWbIsdx7vS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "learning_rate_base = 0.8 # learning_rate会decay, 这个是最初的learning_rate\n",
        "learning_rate_decay = 0.99  # learning_rate decay的参数\n",
        "regularization_rate = 0.0001 # 对weights进行正则项的参数\n",
        "training_steps = 30000 # 一共训多少次，这个不是epoch，而是每一个batch_size算一次\n",
        "moving_average_decay = 0.99 # 参与训练的参数的滑动平均参数\n",
        "\n",
        "model_save_path = \"/content/drive/My Drive/model_folder/test_model4/\"\n",
        "model_name = \"model.ckpt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g0aJ9HQyX9N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "29034a7c-8faa-45d6-81ce-683d20e20c3b"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # 这一步是连接google drivea"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt8FabPJygGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "cc3daadf-fe90-4094-d0b9-586b81a58aca"
      },
      "source": [
        "import os\n",
        "print(os.path.exists(\"/content/drive/My Drive/model_folder/test_model3/\"))\n",
        "print(os.path.exists(\"/content/drive/My Drive/model_folder/test_model4/\"))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um8Ff-tpzXwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(mnist):\n",
        "  x = tf.placeholder(tf.float32, [None, input_node], name=\"x-input\")\n",
        "  y_ = tf.placeholder(tf.float32, [None, 10], name=\"y-input\")\n",
        "  \n",
        "  regularizer = tf.contrib.layers.l2_regularizer(regularization_rate)\n",
        "  \n",
        "  y = inference(x, regularizer)\n",
        "  \n",
        "  global_step = tf.Variable(0, trainable=False)\n",
        "  variables_averages = tf.train.ExponentialMovingAverage(moving_average_decay, global_step)\n",
        "  variables_averages_op = variables_averages.apply(tf.trainable_variables())\n",
        "  \n",
        "  cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.argmax(y_,1), logits=y)\n",
        "  cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
        "  loss = cross_entropy_mean + tf.add_n(tf.get_collection(\"losses\"))\n",
        "\n",
        "  learning_rate = tf.train.exponential_decay(learning_rate_base, global_step, mnist.train.num_examples/batch_size, learning_rate_decay)\n",
        "  \n",
        "  train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
        "  with tf.control_dependencies([train_step, variables_averages_op]):\n",
        "    train_op = tf.no_op(name=\"train\")\n",
        "    \n",
        "  saver = tf.train.Saver()\n",
        "  \n",
        "  with tf.Session() as sess:\n",
        "    tf.global_variables_initializer().run()\n",
        "    \n",
        "    for i in range(training_steps):\n",
        "      xs, ys = mnist.train.next_batch(batch_size)\n",
        "      _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict={x:xs, y_:ys})\n",
        "      \n",
        "      if i % 1000 == 0:\n",
        "        print(\"After %d training steps, loss on training batch is %g\"%(step, loss_value))\n",
        "        \n",
        "        # 训练1000轮之后得到的模型\n",
        "        # 注意，保存模型的时候，还给出了训练的轮数，也就是global_step参数，这样，保存出来的模型就是类似于model.ckpt-1000这样的；\n",
        "        saver.save(sess, os.path.join(model_save_path, model_name), global_step=global_step)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EovUdSHf2nI6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "bb269da5-3599-46f8-80d1-b59e4ba4a2c5"
      },
      "source": [
        "mnist = input_data.read_data_sets(\"./MNIST\", one_hot=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/train-images-idx3-ubyte.gz\n",
            "Extracting ./MNIST/train-labels-idx1-ubyte.gz\n",
            "Extracting ./MNIST/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./MNIST/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grbdPrGQ2xmx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "064937c5-b173-40ab-d7a5-24430e4eccd0"
      },
      "source": [
        "print(mnist.train.num_examples)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnmqBFvI213J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "outputId": "65af1135-8ee0-4430-b4b7-9c2e595b15a5"
      },
      "source": [
        "train(mnist)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0901 03:25:45.995540 140274740156288 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "After 1 training steps, loss on training batch is 3.57218\n",
            "After 1001 training steps, loss on training batch is 0.223444\n",
            "After 2001 training steps, loss on training batch is 0.149209\n",
            "After 3001 training steps, loss on training batch is 0.162809\n",
            "After 4001 training steps, loss on training batch is 0.1277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0901 03:26:16.466108 140274740156288 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "After 5001 training steps, loss on training batch is 0.142235\n",
            "After 6001 training steps, loss on training batch is 0.0959694\n",
            "After 7001 training steps, loss on training batch is 0.0862885\n",
            "After 8001 training steps, loss on training batch is 0.0868254\n",
            "After 9001 training steps, loss on training batch is 0.0780453\n",
            "After 10001 training steps, loss on training batch is 0.0672748\n",
            "After 11001 training steps, loss on training batch is 0.0638042\n",
            "After 12001 training steps, loss on training batch is 0.0610936\n",
            "After 13001 training steps, loss on training batch is 0.0520225\n",
            "After 14001 training steps, loss on training batch is 0.0513625\n",
            "After 15001 training steps, loss on training batch is 0.0545524\n",
            "After 16001 training steps, loss on training batch is 0.0446302\n",
            "After 17001 training steps, loss on training batch is 0.0523867\n",
            "After 18001 training steps, loss on training batch is 0.0435585\n",
            "After 19001 training steps, loss on training batch is 0.0457951\n",
            "After 20001 training steps, loss on training batch is 0.0404386\n",
            "After 21001 training steps, loss on training batch is 0.036551\n",
            "After 22001 training steps, loss on training batch is 0.0393161\n",
            "After 23001 training steps, loss on training batch is 0.0362019\n",
            "After 24001 training steps, loss on training batch is 0.0378497\n",
            "After 25001 training steps, loss on training batch is 0.0369335\n",
            "After 26001 training steps, loss on training batch is 0.0351736\n",
            "After 27001 training steps, loss on training batch is 0.0364835\n",
            "After 28001 training steps, loss on training batch is 0.0355882\n",
            "After 29001 training steps, loss on training batch is 0.0374046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPlEvbnL23M9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}