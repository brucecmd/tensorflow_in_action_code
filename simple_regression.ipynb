{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brucecmd/tensorflow_in_action_code/blob/master/simple_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9FzPBZELY5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from numpy.random import RandomState"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SE4zFTxRVwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1 = tf.Variable(tf.random_normal(shape=[2, 3], dtype=tf.float32), name=\"w1\")\n",
        "w2 = tf.Variable(tf.random_normal(shape=[3, 1], dtype=tf.float32), name=\"w2\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_1yjHT6Rr17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(dtype=tf.float32, shape=(None, 2), name=\"input-x\")\n",
        "y_ = tf.placeholder(dtype=tf.float32, shape=(None, 1), name=\"input-y\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiN1eCefSK6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tf.matmul(x, w1)\n",
        "y = tf.matmul(a, w2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQu4nevASP8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1)))\n",
        "train_step = tf.train.AdamOptimizer(0.001).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZOyGf_WSuez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdm = RandomState(1)\n",
        "X = rdm.rand(2000, 2)\n",
        "Y = [[int(x1+x2)< 1] for (x1, x2) in X] # 这里注意for前面一定要加一个中括号，不然shape对不上"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqUu4SGTTJOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "28f6a42d-e507-432e-d9ef-ba3fc2aa3c21"
      },
      "source": [
        "BATCH_SIZE=10\n",
        "EPOCH=5000\n",
        "DATASET_SIZE=2000\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  tf.global_variables_initializer().run()\n",
        "  for i in range(EPOCH):\n",
        "    start = (i * BATCH_SIZE) % DATASET_SIZE\n",
        "    end = min((start + BATCH_SIZE), DATASET_SIZE)\n",
        "    sess.run(train_step, feed_dict={x:X[start:end], y_:Y[start:end]})\n",
        "    if i % 100 == 0:\n",
        "      total_loss = sess.run(loss, feed_dict={x:X, y_:Y})\n",
        "      print(\"after %d epoch, total_loss %f\"%(i, total_loss))\n",
        "  print(sess.run(w1))\n",
        "  print(sess.run(w2))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "after 0 epoch, total_loss 11.328730\n",
            "after 100 epoch, total_loss 11.328730\n",
            "after 200 epoch, total_loss 11.328730\n",
            "after 300 epoch, total_loss 11.328730\n",
            "after 400 epoch, total_loss 11.328730\n",
            "after 500 epoch, total_loss 11.328730\n",
            "after 600 epoch, total_loss 11.328730\n",
            "after 700 epoch, total_loss 11.328730\n",
            "after 800 epoch, total_loss 11.328730\n",
            "after 900 epoch, total_loss 11.328730\n",
            "after 1000 epoch, total_loss 11.328730\n",
            "after 1100 epoch, total_loss 11.328730\n",
            "after 1200 epoch, total_loss 11.328730\n",
            "after 1300 epoch, total_loss 11.328730\n",
            "after 1400 epoch, total_loss 11.328730\n",
            "after 1500 epoch, total_loss 11.328730\n",
            "after 1600 epoch, total_loss 11.328730\n",
            "after 1700 epoch, total_loss 11.328730\n",
            "after 1800 epoch, total_loss 11.328730\n",
            "after 1900 epoch, total_loss 11.328730\n",
            "after 2000 epoch, total_loss 11.328730\n",
            "after 2100 epoch, total_loss 11.328730\n",
            "after 2200 epoch, total_loss 11.328730\n",
            "after 2300 epoch, total_loss 11.328730\n",
            "after 2400 epoch, total_loss 11.328730\n",
            "after 2500 epoch, total_loss 11.328730\n",
            "after 2600 epoch, total_loss 11.328730\n",
            "after 2700 epoch, total_loss 11.328730\n",
            "after 2800 epoch, total_loss 11.328730\n",
            "after 2900 epoch, total_loss 11.328730\n",
            "after 3000 epoch, total_loss 11.328730\n",
            "after 3100 epoch, total_loss 11.328730\n",
            "after 3200 epoch, total_loss 11.328730\n",
            "after 3300 epoch, total_loss 11.328730\n",
            "after 3400 epoch, total_loss 11.328730\n",
            "after 3500 epoch, total_loss 11.328730\n",
            "after 3600 epoch, total_loss 11.328730\n",
            "after 3700 epoch, total_loss 11.328730\n",
            "after 3800 epoch, total_loss 11.328730\n",
            "after 3900 epoch, total_loss 11.328730\n",
            "after 4000 epoch, total_loss 11.328730\n",
            "after 4100 epoch, total_loss 11.328730\n",
            "after 4200 epoch, total_loss 11.328730\n",
            "after 4300 epoch, total_loss 11.328730\n",
            "after 4400 epoch, total_loss 11.328730\n",
            "after 4500 epoch, total_loss 11.328730\n",
            "after 4600 epoch, total_loss 11.328730\n",
            "after 4700 epoch, total_loss 11.328730\n",
            "after 4800 epoch, total_loss 11.328730\n",
            "after 4900 epoch, total_loss 11.328730\n",
            "[[-1.3418052  -1.1185529  -0.16849305]\n",
            " [-0.23163362  0.06166328  0.496752  ]]\n",
            "[[ 0.31194228]\n",
            " [ 0.02407611]\n",
            " [-0.32192025]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZbXdt1AVeAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}